{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylangacq as pla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pla.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import string\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_seq_items = 2000\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/renee/Documents/CT_Fa18/Spec/Trace'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore header for easier (ordinal) columnar indexing\n",
    "datasheet = pd.read_excel('CogData_FU_82818.xlsx',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row Indices of Memory Responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore first (header) column\n",
    "memory_ix = datasheet.iloc[1:][datasheet.iloc[1:,2].notnull()].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record IDs of Memory Respondents [Analyze all scores from each participant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_id = list(datasheet.iloc[memory_ix][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tech respondents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_ix = datasheet.iloc[1:][datasheet.iloc[1:,3].notnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_id = list(datasheet.iloc[tech_ix][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each respondent responded to one prompt\n",
    "len(tech_id) == len(set(tech_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_id_series = pd.Series(tech_id,index=tech_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total MMSE score'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasheet.iloc[0][74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_score_latest_completed = pickle.load(open('ix_score_latest_completed.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_score_latest_completed = []\n",
    "for ix in tech_id:\n",
    "    slice_ix = list(datasheet[datasheet[0]==ix].index)\n",
    "#     while datasheet.iloc[max(slice_ix)][96] != 'Complete':\n",
    "    # if there is no mmse score, take most recent score\n",
    "    while np.isnan(datasheet.iloc[max(slice_ix)][74]):\n",
    "        slice_ix.remove(max(slice_ix))\n",
    "    ix_score_latest_completed += [max(slice_ix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_ix_score_latest_completed = [i for i in ix_score_latest_completed if datasheet.iloc[i,0] in memory_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_mmse = pd.Series([y for y in datasheet.iloc[ix_score_latest_completed,74]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ix by samples \n",
    "tech_mmse_dict = {ix:score for (ix,score) in zip(tech_ix,tech_mmse)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tech_mmse_dict,'tech_mmse_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_mmse = pd.Series([y for y in datasheet.iloc[mem_ix_score_latest_completed,74]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_mmse_dict = {ix:score for (ix,score) in zip(memory_ix,mem_mmse)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mem_mmse_dict,'mem_mmse_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load addb vocab glove word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = './FinalProj/PretrainedWordEmb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "addbvocab = pickle.load(open(f'{glove_path}/addb.vocab_emb.glove.42B.300.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './FinalProj/PretrainedWordEmb//addb.vocab.glove.42B.300_words.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-983221339998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maddbvocab_legacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{glove_path}/addb.vocab.glove.42B.300_words.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './FinalProj/PretrainedWordEmb//addb.vocab.glove.42B.300_words.pkl'"
     ]
    }
   ],
   "source": [
    "addbvocab_legacy = pickle.load(open(f'{glove_path}/addb.vocab.glove.42B.300_words.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addbvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addbvocab['I'] != addbvocab_legacy['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eq() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:\n",
      " * (Tensor other)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[31;1mnumpy.ndarray\u001b[0m)\n",
      " * (Number other)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[31;1mnumpy.ndarray\u001b[0m)\n",
      "\n",
      "CLITIC\n",
      "tensor([-6.7711e-03, -2.3817e-03,  2.4845e-02,  3.8487e-02, -1.2772e-01,\n",
      "         3.3165e-02,  4.8666e-01, -1.6021e-01,  1.6853e-02,  1.6322e-01,\n",
      "        -1.0224e-01, -5.2618e-02,  3.4685e-02, -1.9040e-02,  3.2686e-02,\n",
      "         3.5499e-02,  6.3939e-02,  3.8428e-02, -1.1650e-02, -2.5398e-03,\n",
      "        -1.5485e-02, -2.3090e-02,  1.1053e-02, -2.8602e-02, -2.3924e-02,\n",
      "         5.4396e-02, -2.7256e-03,  2.9342e-02,  3.3936e-02,  5.7305e-02,\n",
      "         5.9507e-02,  1.0920e-04, -2.3985e-02,  2.5953e-02,  1.0569e-02,\n",
      "         7.6946e-03,  1.8665e-02,  1.7798e-02, -2.5355e-02,  2.4376e-02,\n",
      "         2.5437e-02, -5.5402e-02,  2.5985e-02,  4.1344e-02,  1.8730e-02,\n",
      "         3.6826e-03, -3.2120e-02,  5.6875e-02,  4.6870e-02, -1.3394e-02,\n",
      "        -1.4460e-03,  4.7467e-04,  2.6838e-02,  8.0426e-06, -2.1895e-02,\n",
      "         1.8322e-02, -3.3935e-02, -2.6631e-02,  2.2321e-02, -1.9475e-05,\n",
      "         7.3048e-03,  2.9189e-02, -2.0734e-02, -1.1434e-02,  1.0040e-02,\n",
      "        -2.9709e-02, -6.2757e-03, -4.6265e-02, -4.0179e-02,  3.4336e-02,\n",
      "         7.7573e-02, -2.9712e-02, -1.6156e-02,  9.8200e-03,  1.0996e-02,\n",
      "         7.2783e-02, -3.2693e-02, -3.1668e-02, -1.8598e-02,  2.7129e-02,\n",
      "        -2.0828e-02,  2.2916e-01, -3.2600e-03,  5.9076e-02, -3.6557e-02,\n",
      "        -3.1909e-02, -4.3888e-02,  1.8601e-02, -3.8202e-03,  2.2831e-02,\n",
      "        -5.7948e-04,  4.6076e-02,  5.8365e-03, -5.5786e-03, -1.8426e-02,\n",
      "         1.9070e-01,  4.5444e-01,  1.6276e-02, -3.3623e-02, -1.6447e-02,\n",
      "         1.2305e-02, -7.2236e-02, -6.4585e-02, -1.2625e-02,  1.9059e-02,\n",
      "         2.3224e-02, -3.5476e-02, -2.5446e-03,  3.7693e-03,  2.1223e-02,\n",
      "         5.9036e-03, -9.4872e-04, -1.7324e-02, -1.5915e-02,  6.9584e-02,\n",
      "        -5.9973e-02, -1.1616e-01, -9.1350e-03, -6.2911e-03, -5.0648e-02,\n",
      "         4.6316e-02,  2.8032e-02, -1.8105e-02,  6.1553e-02, -7.7239e-03,\n",
      "         2.6889e-02, -4.0427e-03,  2.9589e-02,  1.4475e-02,  3.0894e-02,\n",
      "        -1.7540e-02, -2.4537e-02,  3.0165e-02,  2.3762e-02, -7.4301e-02,\n",
      "        -1.7090e-02, -2.3775e-02, -5.4935e-03, -3.9262e-02, -2.7193e-01,\n",
      "        -7.7345e-03, -2.7051e-02, -2.1302e-02, -3.7742e-03,  2.4750e-03,\n",
      "         4.4947e-02, -2.8158e-02,  2.1787e-02, -1.2270e-01, -1.9199e-02,\n",
      "         9.0202e-03,  2.7334e-02, -8.6760e-03,  2.3952e-02, -3.9743e-02,\n",
      "         6.3233e-02,  2.6596e-02, -2.6011e-02,  4.1268e-02,  3.1507e-02,\n",
      "        -1.7383e-02,  1.2801e-02,  4.0318e-02,  3.0069e-02, -4.1490e-03,\n",
      "         2.7142e-04, -1.3414e-03, -1.9703e-02, -4.1014e-02,  8.0866e-02,\n",
      "         3.8820e-03,  1.2987e-02,  2.9585e-02,  2.1751e-02,  3.9705e-02,\n",
      "        -6.7644e-02,  2.8961e-02,  3.3712e-02, -5.6041e-02,  1.4678e-02,\n",
      "         1.3548e-02, -4.8581e-02,  7.8216e-03,  3.2894e-02, -2.8622e-02,\n",
      "         4.4341e-02, -5.3621e-02,  1.8796e-02, -1.8202e-02, -3.3977e-03,\n",
      "        -3.1241e-02,  4.1629e-02, -5.8006e-02,  2.1002e-02,  1.4295e-02,\n",
      "         3.9106e-02, -3.8101e-02, -1.9037e-02, -3.1913e-02,  5.7362e-02,\n",
      "         5.0169e-02,  2.0908e-04,  1.3736e-02, -2.7328e-02, -1.6885e-02,\n",
      "        -3.8193e-02, -1.9489e-02, -3.3413e-02, -6.6495e-02,  1.7381e-02,\n",
      "        -4.8202e-02,  2.8117e-02,  7.8632e-02,  3.0881e-02, -2.2783e-03,\n",
      "         1.4133e-02,  1.5680e-02,  4.7377e-02,  1.4976e-02,  1.1558e-02,\n",
      "         4.9961e-02,  1.9379e-02,  1.0125e-02, -2.6128e-02,  5.1457e-01,\n",
      "        -3.7102e-02,  4.4867e-02,  4.0055e-03,  6.8305e-03,  2.6791e-02,\n",
      "        -4.3027e-02, -1.4539e-02, -2.4273e-02,  4.0522e-03,  1.0821e-02,\n",
      "        -5.0199e-02, -1.1919e-02, -1.5112e-02,  5.2869e-02,  5.4153e-02,\n",
      "         1.8666e-02, -9.8638e-03,  7.3563e-02, -1.0613e-01,  3.1946e-03,\n",
      "         2.8483e-02, -2.6555e-02,  7.1444e-02,  3.2869e-02, -4.2948e-02,\n",
      "         7.1629e-03,  2.5399e-02,  5.9469e-02, -1.3297e-02,  1.0383e-02,\n",
      "         5.0468e-03, -1.2967e-02, -1.7890e-03, -5.0442e-02, -5.8529e-02,\n",
      "        -3.5609e-02,  1.3422e-02,  1.3791e-02, -3.2426e-03, -4.9554e-02,\n",
      "         3.2089e-03,  4.3197e-02,  2.6821e-02, -2.5876e-02,  4.5916e-03,\n",
      "        -1.0840e-02,  3.1969e-02,  8.1694e-02, -4.5622e-02,  1.6733e-03,\n",
      "        -3.1976e-02, -4.2784e-02, -3.4856e-02, -4.7064e-02,  2.6085e-02,\n",
      "        -1.7271e-01,  3.5262e-02, -1.0843e-02, -4.2731e-02,  2.1936e-02,\n",
      "        -1.4895e-02, -3.8460e-03, -2.5388e-02,  2.3178e-02,  3.3305e-02,\n",
      "        -4.2066e-03,  1.2332e-02,  5.8009e-02,  2.2685e-02,  2.0582e-03,\n",
      "         1.5814e-02,  1.6214e-02,  1.0196e-02, -4.4902e-02,  1.9747e-02],\n",
      "       dtype=torch.float64)\n",
      "[-6.77110762e-03 -2.38171602e-03  2.48453616e-02  3.84871991e-02\n",
      " -1.27718938e-01  3.31646344e-02  4.86656168e-01 -1.60207891e-01\n",
      "  1.68529167e-02  1.63224430e-01 -1.02243697e-01 -5.26176498e-02\n",
      "  3.46847772e-02 -1.90403945e-02  3.26858599e-02  3.54991079e-02\n",
      "  6.39390293e-02  3.84283555e-02 -1.16503242e-02 -2.53978575e-03\n",
      " -1.54851111e-02 -2.30899176e-02  1.10525923e-02 -2.86016257e-02\n",
      " -2.39241718e-02  5.43962499e-02 -2.72564042e-03  2.93424213e-02\n",
      "  3.39359506e-02  5.73053679e-02  5.95071778e-02  1.09199854e-04\n",
      " -2.39850050e-02  2.59529588e-02  1.05694563e-02  7.69458290e-03\n",
      "  1.86652275e-02  1.77983629e-02 -2.53548389e-02  2.43759036e-02\n",
      "  2.54368294e-02 -5.54019334e-02  2.59849416e-02  4.13441975e-02\n",
      "  1.87303416e-02  3.68259799e-03 -3.21201589e-02  5.68750757e-02\n",
      "  4.68697892e-02 -1.33935990e-02 -1.44603463e-03  4.74672429e-04\n",
      "  2.68379948e-02  8.04257735e-06 -2.18948008e-02  1.83219156e-02\n",
      " -3.39346471e-02 -2.66306850e-02  2.23212386e-02 -1.94754142e-05\n",
      "  7.30479271e-03  2.91891943e-02 -2.07341701e-02 -1.14342526e-02\n",
      "  1.00404227e-02 -2.97088102e-02 -6.27568220e-03 -4.62653886e-02\n",
      " -4.01785483e-02  3.43360887e-02  7.75729199e-02 -2.97119579e-02\n",
      " -1.61555066e-02  9.81997711e-03  1.09959206e-02  7.27834333e-02\n",
      " -3.26932356e-02 -3.16679919e-02 -1.85980662e-02  2.71294022e-02\n",
      " -2.08284118e-02  2.29159121e-01 -3.26001224e-03  5.90762854e-02\n",
      " -3.65571039e-02 -3.19088863e-02 -4.38883460e-02  1.86008575e-02\n",
      " -3.82020500e-03  2.28310218e-02 -5.79479237e-04  4.60758459e-02\n",
      "  5.83652500e-03 -5.57860711e-03 -1.84264244e-02  1.90696922e-01\n",
      "  4.54442770e-01  1.62763339e-02 -3.36225875e-02 -1.64473133e-02\n",
      "  1.23053757e-02 -7.22361191e-02 -6.45849375e-02 -1.26253468e-02\n",
      "  1.90587309e-02  2.32239948e-02 -3.54756578e-02 -2.54456504e-03\n",
      "  3.76931571e-03  2.12225100e-02  5.90359614e-03 -9.48715915e-04\n",
      " -1.73244880e-02 -1.59153684e-02  6.95839599e-02 -5.99729115e-02\n",
      " -1.16157052e-01 -9.13497444e-03 -6.29112099e-03 -5.06480270e-02\n",
      "  4.63160272e-02  2.80320415e-02 -1.81048932e-02  6.15529271e-02\n",
      " -7.72394559e-03  2.68893056e-02 -4.04274634e-03  2.95890387e-02\n",
      "  1.44753530e-02  3.08942256e-02 -1.75404121e-02 -2.45371171e-02\n",
      "  3.01654994e-02  2.37621137e-02 -7.43010617e-02 -1.70904803e-02\n",
      " -2.37747460e-02 -5.49349870e-03 -3.92616127e-02 -2.71933603e-01\n",
      " -7.73449005e-03 -2.70511382e-02 -2.13022814e-02 -3.77421298e-03\n",
      "  2.47498051e-03  4.49467284e-02 -2.81584745e-02  2.17868442e-02\n",
      " -1.22703600e-01 -1.91991291e-02  9.02017781e-03  2.73343587e-02\n",
      " -8.67601421e-03  2.39519202e-02 -3.97425078e-02  6.32328110e-02\n",
      "  2.65959717e-02 -2.60106547e-02  4.12680322e-02  3.15069673e-02\n",
      " -1.73832024e-02  1.28012840e-02  4.03177492e-02  3.00692966e-02\n",
      " -4.14899192e-03  2.71421716e-04 -1.34144745e-03 -1.97032067e-02\n",
      " -4.10139589e-02  8.08664683e-02  3.88196873e-03  1.29874651e-02\n",
      "  2.95845523e-02  2.17512555e-02  3.97052874e-02 -6.76439591e-02\n",
      "  2.89607355e-02  3.37118624e-02 -5.60413893e-02  1.46780557e-02\n",
      "  1.35475817e-02 -4.85808646e-02  7.82162974e-03  3.28944609e-02\n",
      " -2.86215475e-02  4.43414751e-02 -5.36211095e-02  1.87957011e-02\n",
      " -1.82017676e-02 -3.39765938e-03 -3.12413547e-02  4.16291291e-02\n",
      " -5.80057705e-02  2.10018224e-02  1.42951982e-02  3.91055608e-02\n",
      " -3.81014269e-02 -1.90372487e-02 -3.19134805e-02  5.73617553e-02\n",
      "  5.01687363e-02  2.09082800e-04  1.37361011e-02 -2.73275728e-02\n",
      " -1.68846718e-02 -3.81932100e-02 -1.94893978e-02 -3.34131622e-02\n",
      " -6.64952871e-02  1.73808842e-02 -4.82017718e-02  2.81172597e-02\n",
      "  7.86318751e-02  3.08807584e-02 -2.27833121e-03  1.41326143e-02\n",
      "  1.56801616e-02  4.73774721e-02  1.49755144e-02  1.15575185e-02\n",
      "  4.99614091e-02  1.93791456e-02  1.01249449e-02 -2.61276999e-02\n",
      "  5.14571579e-01 -3.71022793e-02  4.48672177e-02  4.00549217e-03\n",
      "  6.83049122e-03  2.67905141e-02 -4.30270087e-02 -1.45387436e-02\n",
      " -2.42727143e-02  4.05219157e-03  1.08208256e-02 -5.01988612e-02\n",
      " -1.19188736e-02 -1.51124541e-02  5.28685385e-02  5.41534022e-02\n",
      "  1.86664811e-02 -9.86383330e-03  7.35627800e-02 -1.06134407e-01\n",
      "  3.19457609e-03  2.84830015e-02 -2.65548702e-02  7.14437106e-02\n",
      "  3.28689574e-02 -4.29476699e-02  7.16287049e-03  2.53985457e-02\n",
      "  5.94688893e-02 -1.32974624e-02  1.03833337e-02  5.04675816e-03\n",
      " -1.29671793e-02 -1.78901811e-03 -5.04415269e-02 -5.85285383e-02\n",
      " -3.56088732e-02  1.34219344e-02  1.37912793e-02 -3.24261944e-03\n",
      " -4.95543864e-02  3.20889100e-03  4.31969978e-02  2.68213345e-02\n",
      " -2.58762786e-02  4.59164129e-03 -1.08397825e-02  3.19686152e-02\n",
      "  8.16940450e-02 -4.56220196e-02  1.67329328e-03 -3.19761515e-02\n",
      " -4.27843891e-02 -3.48558462e-02 -4.70641807e-02  2.60851811e-02\n",
      " -1.72713540e-01  3.52618368e-02 -1.08433818e-02 -4.27312883e-02\n",
      "  2.19364354e-02 -1.48951291e-02 -3.84595062e-03 -2.53876170e-02\n",
      "  2.31781806e-02  3.33054528e-02 -4.20659181e-03  1.23324072e-02\n",
      "  5.80088647e-02  2.26852796e-02  2.05819848e-03  1.58144669e-02\n",
      "  1.62143396e-02  1.01961696e-02 -4.49022512e-02  1.97468221e-02]\n"
     ]
    }
   ],
   "source": [
    "for k in addbvocab.keys():\n",
    "\n",
    "    try:\n",
    "        if not torch.all(addbvocab[k].eq(addbvocab_legacy[k])):\n",
    "            print(k)\n",
    "            print(addbvocab[k])\n",
    "            print(addbvocab_legacy[k])\n",
    "    except TypeError as t:\n",
    "        print(t)\n",
    "        print(k)\n",
    "        print(addbvocab[k])\n",
    "        print(addbvocab_legacy[k])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addbvocab.keys() == addbvocab_legacy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-67-dddad3ac77dd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-dddad3ac77dd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [v,vl for (v,vl) in zip(addbvocab,addbvocab_legacy) ]\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[v,vl for (v,vl) in zip(addbvocab,addbvocab_legacy) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/367155/splitting-a-string-into-words-and-punctuation -first comment\n",
    "# The trick is, not to think about where to split the string, but what to include in the tokens.\n",
    "# Put any additional punctuation marks you want to use in the right half of the regular expression.\n",
    "# Anything not explicitely mentioned in the re is silently dropped.\n",
    "\n",
    "# returns nested sentence\n",
    "\n",
    "def list_tokenize(document):\n",
    "#     return re.sub('['+string.punctuation.replace('\\'','')+']',' ',response).split()\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    \n",
    "    return [nltk.word_tokenize(sent) for sent in sentences]\n",
    "#     return re.findall(r\"[\\w']+|[^\\s\\w]\",response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#information-extraction\n",
    "#https://www.nltk.org/book/ch07.html\n",
    "def get_pos(document):\n",
    "    #sentence segmentation\n",
    "    sentences = nltk.sent_tokenize(document) \n",
    "    #tokenization\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    #pos tagging\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences] \n",
    "    \n",
    "    pos_list = [p for sent in sentences for (t,p) in sent]\n",
    "    return pos_list\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRP$',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'CC',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'VBD',\n",
       " ',',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " \"''\",\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'JJS',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'IN',\n",
       " '$',\n",
       " 'CD',\n",
       " ',',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'VB',\n",
       " '.',\n",
       " \"''\",\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'VBG',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'WRB',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'VBG',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ':',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'VBD',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'PRP$',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'VBD',\n",
       " 'RB',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'JJ',\n",
       " ',',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'VBG',\n",
       " 'RB',\n",
       " '.']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pos(datasheet.iloc[memory_ix[3],2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['When',\n",
       "  'I',\n",
       "  'was',\n",
       "  'a',\n",
       "  'little',\n",
       "  'child',\n",
       "  'I',\n",
       "  'had',\n",
       "  'the',\n",
       "  'same',\n",
       "  'experience',\n",
       "  'over',\n",
       "  'and',\n",
       "  'over',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'always',\n",
       "  'occurred',\n",
       "  'between',\n",
       "  'being',\n",
       "  'awake',\n",
       "  'and',\n",
       "  'asleep',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'experience',\n",
       "  'had',\n",
       "  'no',\n",
       "  'words',\n",
       "  '...',\n",
       "  'it',\n",
       "  'was',\n",
       "  'all',\n",
       "  'sensation',\n",
       "  '.'],\n",
       " ['At',\n",
       "  'a',\n",
       "  'point',\n",
       "  'between',\n",
       "  'my',\n",
       "  'eyes',\n",
       "  'I',\n",
       "  'got',\n",
       "  'a',\n",
       "  'feeling',\n",
       "  'of',\n",
       "  'all',\n",
       "  'space',\n",
       "  'expanding',\n",
       "  'and',\n",
       "  'expanding',\n",
       "  'until',\n",
       "  'it',\n",
       "  'became',\n",
       "  'so',\n",
       "  'vast',\n",
       "  'I',\n",
       "  'was',\n",
       "  'terrified',\n",
       "  '.'],\n",
       " ['Then',\n",
       "  'all',\n",
       "  'space',\n",
       "  'would',\n",
       "  'contract',\n",
       "  'until',\n",
       "  'it',\n",
       "  'became',\n",
       "  'so',\n",
       "  'tiny',\n",
       "  'I',\n",
       "  'would',\n",
       "  'be',\n",
       "  'terrified',\n",
       "  '.'],\n",
       " ['I',\n",
       "  'was',\n",
       "  'both',\n",
       "  'afraid',\n",
       "  'of',\n",
       "  'having',\n",
       "  'this',\n",
       "  'experience',\n",
       "  'and',\n",
       "  'welcomed',\n",
       "  'it',\n",
       "  '.']]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tokenize(datasheet.iloc[memory_ix[0],2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRB\n",
      "PRP\n",
      "VBD\n",
      "RB\n",
      "JJ\n",
      ",\n",
      "VBG\n",
      "IN\n",
      "DT\n",
      "NNP\n",
      "NN\n",
      "IN\n",
      "NNP\n",
      ",\n",
      "PRP$\n",
      "NNS\n",
      "VBD\n",
      "PRP$\n",
      "JJ\n",
      "NN\n",
      "CC\n",
      "PRP\n",
      "TO\n",
      "DT\n",
      "JJ\n",
      "JJ\n",
      "VBG\n",
      "NN\n",
      ".\n",
      "PRP\n",
      "RB\n",
      "VBD\n",
      "JJ\n",
      ":\n",
      "RB\n",
      "RB\n",
      "IN\n",
      "DT\n",
      "NN\n",
      "POS\n",
      "NN\n",
      ":\n",
      "VBN\n",
      "IN\n",
      "DT\n",
      "NNP\n",
      "TO\n",
      "VB\n",
      "NNS\n",
      "IN\n",
      "VBG\n",
      "NN\n",
      "NNP\n",
      "NNP\n",
      ".\n",
      "DT\n",
      "NN\n",
      "VBD\n",
      "RB\n",
      "JJ\n",
      ".\n",
      "DT\n",
      "NN\n",
      "VBD\n",
      "JJ\n",
      ",\n",
      "JJ\n",
      "VBD\n",
      "JJ\n",
      "NN\n",
      ",\n",
      "CC\n",
      "VBD\n",
      "DT\n",
      "JJ\n",
      "JJ\n",
      "NN\n",
      "WRB\n",
      "NNS\n",
      "MD\n",
      "VB\n",
      ".\n",
      "PRP\n",
      "VBP\n",
      "DT\n",
      "NN\n",
      ",\n",
      "DT\n",
      "JJ\n",
      "NN\n",
      ",\n",
      "DT\n",
      "NN\n",
      "IN\n",
      "DT\n",
      "NN\n",
      ",\n",
      "DT\n",
      "NN\n",
      "IN\n",
      "DT\n",
      "NN\n",
      ".\n",
      "VBG\n",
      "CC\n",
      "NN\n",
      "CC\n",
      "VBG\n",
      "VBP\n",
      "VBN\n",
      "DT\n",
      "JJ\n",
      "NN\n",
      "IN\n",
      "PRP$\n",
      "NN\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for sent in get_pos(datasheet.iloc[memory_ix[1],2]):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WRB',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " ',',\n",
       " 'VBG',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'VBD',\n",
       " 'PRP$',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'VBG',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'RB',\n",
       " 'VBD',\n",
       " 'JJ',\n",
       " ':',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'POS',\n",
       " 'NN',\n",
       " ':',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'VBG',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'JJ',\n",
       " ',',\n",
       " 'JJ',\n",
       " 'VBD',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'WRB',\n",
       " 'NNS',\n",
       " 'MD',\n",
       " 'VB',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VBG',\n",
       " 'CC',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'VBG',\n",
       " 'VBP',\n",
       " 'VBN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " '.']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for sent in pos_preprocess(datasheet.iloc[memory_ix[1],2]) for (t,p) in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             Record ID\n",
       "1                                            Event Name\n",
       "2     Write a short sketch about a memory from your ...\n",
       "3     How does technology and social media impact th...\n",
       "4                   Date of Neurobehavioral Status Exam\n",
       "                            ...                        \n",
       "92                         Cog State: One Back Accuracy\n",
       "93                          Ravens Progressive Matrices\n",
       "94                                Logical Memory Part B\n",
       "95                         East Boston Immediate Recall\n",
       "96                                            Complete?\n",
       "Name: 0, Length: 97, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasheet.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tokenize(datasheet.iloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabset = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I',\n",
       "  'stay',\n",
       "  'in',\n",
       "  'touch',\n",
       "  'with',\n",
       "  'family',\n",
       "  'and',\n",
       "  'friends',\n",
       "  'through',\n",
       "  'email',\n",
       "  '.']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tokenize(datasheet.iloc[tech_ix[0],3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for corpus,data in [(cookie_fnames,cookie_data),(sentence_fnames,sentence_data)]: \n",
    "for ix in tech_ix:\n",
    "    for sent in list_tokenize(datasheet.iloc[ix,3]):\n",
    "        vocabset.update(sent)\n",
    "#         tokens = set([tokenraw for sent in data.tagged_sents(participant='PAR',by_files=True)[corpus[i]] for (tokenraw,pos,tokenstem,dependency) in sent])\n",
    "#         vocabset.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in memory_ix:\n",
    "    for sent in list_tokenize(datasheet.iloc[ix,2]):\n",
    "        vocabset.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2125"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db Vocab as gloVe emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted(list(addbvocab)) == sorted(list(vocabset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD MOR: POS + GRAMMATICAL CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "posset = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/renee/Documents/CT_Fa18/Spec/Trace'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "addb_posset = torch.load('./FinalProj/pos_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'CM': 1,\n",
       " 'COMP': 2,\n",
       " 'PRO:EXIST': 3,\n",
       " 'IN#ADJ': 4,\n",
       " 'PRE#PART': 5,\n",
       " '.': 6,\n",
       " 'PRE#V': 7,\n",
       " 'OVER#PART': 8,\n",
       " 'UN#ADV': 9,\n",
       " 'PRO:PER': 10,\n",
       " 'ADV:TEM': 11,\n",
       " '+/.': 12,\n",
       " 'V': 13,\n",
       " 'PRO:INT': 14,\n",
       " 'N': 15,\n",
       " 'PRO:POSS': 16,\n",
       " 'N:ADJ': 17,\n",
       " 'DET:DEM': 18,\n",
       " 'END': 19,\n",
       " 'PRO:INDEF': 20,\n",
       " '+\"/.': 21,\n",
       " 'DET:POSS': 22,\n",
       " 'OVER#V': 23,\n",
       " 'DET:ART': 24,\n",
       " 'INF': 25,\n",
       " 'OVER#N:GERUND': 26,\n",
       " 'META': 27,\n",
       " 'ON': 28,\n",
       " 'UP#V': 29,\n",
       " 'MID#N': 30,\n",
       " 'NEG': 31,\n",
       " 'MOD': 32,\n",
       " '+...': 33,\n",
       " 'PRO:SUB': 34,\n",
       " 'UN#PART': 35,\n",
       " 'PREP': 36,\n",
       " 'DET:NUM': 37,\n",
       " 'N:GERUND': 38,\n",
       " '+//?': 39,\n",
       " 'UN#ADJ': 40,\n",
       " 'COP': 41,\n",
       " 'N:PT': 42,\n",
       " 'AUX': 43,\n",
       " 'ADV': 44,\n",
       " 'OUT#PART': 45,\n",
       " '!': 46,\n",
       " 'PRO:OBJ': 47,\n",
       " 'ADJ': 48,\n",
       " 'N:PROP': 49,\n",
       " 'MINI#N': 50,\n",
       " '+/?': 51,\n",
       " '?': 52,\n",
       " 'POST': 53,\n",
       " 'N:LET': 54,\n",
       " 'UN#N': 55,\n",
       " 'UP#PART': 56,\n",
       " 'COORD': 57,\n",
       " 'QN': 58,\n",
       " 'GRAND#N': 59,\n",
       " 'CONJ': 60,\n",
       " '+..?': 61,\n",
       " 'PART': 62,\n",
       " 'BEG': 63,\n",
       " 'PRO:REL': 64,\n",
       " 'PRO:REFL': 65,\n",
       " 'NEO': 66,\n",
       " 'CO': 67,\n",
       " '+\".': 68,\n",
       " 'PRO:DEM': 69,\n",
       " '+//.': 70}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addb_posset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a short sketch about a memory from your childhood and why it is memorable or important to you. Feel free to discuss an event with family or friends, a place you traveled, or a significant time in your life.  Please limit your response to no more than 1-2 paragraphs.  '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasheet.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for corpus,data in [(cookie_fnames,cookie_data),(sentence_fnames,sentence_data)]: \n",
    "for ix in tech_ix:\n",
    "    posset.update(get_pos(datasheet.iloc[ix,3]))\n",
    "#     for i in range(len(corpus)):\n",
    "#         pos = set([pos for sent in data.tagged_sents(participant='PAR',by_files=True)[corpus[i]] for (tokenraw,pos,tokenstem,dependency) in sent])\n",
    "#         posset.update(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in memory_ix:\n",
    "    posset.update(get_pos(datasheet.iloc[ix,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '!',\n",
       " '+\".',\n",
       " '+\"/.',\n",
       " '+...',\n",
       " '+..?',\n",
       " '+/.',\n",
       " '+//.',\n",
       " '+//?',\n",
       " '+/?',\n",
       " '.',\n",
       " '?',\n",
       " 'ADJ',\n",
       " 'ADV',\n",
       " 'ADV:TEM',\n",
       " 'AUX',\n",
       " 'BEG',\n",
       " 'CM',\n",
       " 'CO',\n",
       " 'COMP',\n",
       " 'CONJ',\n",
       " 'COORD',\n",
       " 'COP',\n",
       " 'DET:ART',\n",
       " 'DET:DEM',\n",
       " 'DET:NUM',\n",
       " 'DET:POSS',\n",
       " 'END',\n",
       " 'GRAND#N',\n",
       " 'IN#ADJ',\n",
       " 'INF',\n",
       " 'META',\n",
       " 'MID#N',\n",
       " 'MINI#N',\n",
       " 'MOD',\n",
       " 'N',\n",
       " 'N:ADJ',\n",
       " 'N:GERUND',\n",
       " 'N:LET',\n",
       " 'N:PROP',\n",
       " 'N:PT',\n",
       " 'NEG',\n",
       " 'NEO',\n",
       " 'ON',\n",
       " 'OUT#PART',\n",
       " 'OVER#N:GERUND',\n",
       " 'OVER#PART',\n",
       " 'OVER#V',\n",
       " 'PART',\n",
       " 'POST',\n",
       " 'PRE#PART',\n",
       " 'PRE#V',\n",
       " 'PREP',\n",
       " 'PRO:DEM',\n",
       " 'PRO:EXIST',\n",
       " 'PRO:INDEF',\n",
       " 'PRO:INT',\n",
       " 'PRO:OBJ',\n",
       " 'PRO:PER',\n",
       " 'PRO:POSS',\n",
       " 'PRO:REFL',\n",
       " 'PRO:REL',\n",
       " 'PRO:SUB',\n",
       " 'QN',\n",
       " 'UN#ADJ',\n",
       " 'UN#ADV',\n",
       " 'UN#N',\n",
       " 'UN#PART',\n",
       " 'UP#PART',\n",
       " 'UP#V',\n",
       " 'V'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(addb_posset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$',\n",
       " \"''\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " ':',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'MD',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'POS',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WRB'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$',\n",
       " \"''\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ':',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'MD',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'POS',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WRB'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posset.difference(addb_posset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FW', '(', \"''\", ':', ')', ',', '$']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rm these tokens\n",
    "[v for (k,v) in posdict.items() if v not in addb_posset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$',\n",
       " \"''\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ':',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'MD',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'POS',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WRB'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posset.difference(addb_posset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swap with chat term where poss\n",
    "posdict = {k:k for k in posset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://talkbank.org/manuals/MOR.html#_Toc17967934\n",
    "# https://talkbank.org/manuals/MOR.html#_Toc1313898\n",
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['CC'] = 'CONJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['CD'] = 'DET:NUM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['DT'] = 'DET:ART'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['EX'] = 'PRO:EXIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['IN'] = 'PREP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['JJ'] = 'ADJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['JJR'] = 'ADJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['JJS'] = 'ADJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['MD'] = 'MOD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['NN'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['NNP'] = 'N:PROP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['NNPS'] = 'N:PROP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['NNS'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['PDT'] = 'DET:DEM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['POS'] = 'DET:POSS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['PRP'] = 'PRO:PER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['PRP$'] = 'PRO:POSS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['RB'] = 'ADV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['RBR'] = 'ADV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['RBS'] = 'ADV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['RP'] = 'PART'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['TO'] = 'PREP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['VB'] = 'V'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['VBD'] = 'V'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['VBG'] = 'PART'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['VBN']  = 'PART'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['VBP'] = 'V'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['VBZ'] = 'V'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '!',\n",
       " '+\".',\n",
       " '+\"/.',\n",
       " '+...',\n",
       " '+..?',\n",
       " '+/.',\n",
       " '+//.',\n",
       " '+//?',\n",
       " '+/?',\n",
       " '.',\n",
       " '?',\n",
       " 'ADJ',\n",
       " 'ADV',\n",
       " 'ADV:TEM',\n",
       " 'AUX',\n",
       " 'BEG',\n",
       " 'CM',\n",
       " 'CO',\n",
       " 'COMP',\n",
       " 'CONJ',\n",
       " 'COORD',\n",
       " 'COP',\n",
       " 'DET:ART',\n",
       " 'DET:DEM',\n",
       " 'DET:NUM',\n",
       " 'DET:POSS',\n",
       " 'END',\n",
       " 'GRAND#N',\n",
       " 'IN#ADJ',\n",
       " 'INF',\n",
       " 'META',\n",
       " 'MID#N',\n",
       " 'MINI#N',\n",
       " 'MOD',\n",
       " 'N',\n",
       " 'N:ADJ',\n",
       " 'N:GERUND',\n",
       " 'N:LET',\n",
       " 'N:PROP',\n",
       " 'N:PT',\n",
       " 'NEG',\n",
       " 'NEO',\n",
       " 'ON',\n",
       " 'OUT#PART',\n",
       " 'OVER#N:GERUND',\n",
       " 'OVER#PART',\n",
       " 'OVER#V',\n",
       " 'PART',\n",
       " 'POST',\n",
       " 'PRE#PART',\n",
       " 'PRE#V',\n",
       " 'PREP',\n",
       " 'PRO:DEM',\n",
       " 'PRO:EXIST',\n",
       " 'PRO:INDEF',\n",
       " 'PRO:INT',\n",
       " 'PRO:OBJ',\n",
       " 'PRO:PER',\n",
       " 'PRO:POSS',\n",
       " 'PRO:REFL',\n",
       " 'PRO:REL',\n",
       " 'PRO:SUB',\n",
       " 'QN',\n",
       " 'UN#ADJ',\n",
       " 'UN#ADV',\n",
       " 'UN#N',\n",
       " 'UN#PART',\n",
       " 'UP#PART',\n",
       " 'UP#V',\n",
       " 'V']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(addb_posset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DET:INT not in addb_posseet\n",
    "posdict['WDT'] = 'DET:POSS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict['WP'] = 'PRO:INT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ADV:WH' in addb_posset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADV:WH not in addb_posset\n",
    "posdict['WRB'] = 'ADV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FW', '(', \"''\", ':', ')', ',', '$']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[missing for missing in posset.difference(set(addb_posset.keys())) if posdict[missing] not in set(addb_posset.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(posdict,'apc_pos_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict = torch.load('apc_pos_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '!',\n",
       " '+\".',\n",
       " '+\"/.',\n",
       " '+...',\n",
       " '+..?',\n",
       " '+/.',\n",
       " '+//.',\n",
       " '+//?',\n",
       " '+/?',\n",
       " '?',\n",
       " 'ADJ',\n",
       " 'ADV',\n",
       " 'ADV:TEM',\n",
       " 'AUX',\n",
       " 'BEG',\n",
       " 'CM',\n",
       " 'CO',\n",
       " 'COMP',\n",
       " 'CONJ',\n",
       " 'COORD',\n",
       " 'COP',\n",
       " 'DET:ART',\n",
       " 'DET:DEM',\n",
       " 'DET:NUM',\n",
       " 'DET:POSS',\n",
       " 'END',\n",
       " 'GRAND#N',\n",
       " 'IN#ADJ',\n",
       " 'INF',\n",
       " 'META',\n",
       " 'MID#N',\n",
       " 'MINI#N',\n",
       " 'MOD',\n",
       " 'N',\n",
       " 'N:ADJ',\n",
       " 'N:GERUND',\n",
       " 'N:LET',\n",
       " 'N:PROP',\n",
       " 'N:PT',\n",
       " 'NEG',\n",
       " 'NEO',\n",
       " 'ON',\n",
       " 'OUT#PART',\n",
       " 'OVER#N:GERUND',\n",
       " 'OVER#PART',\n",
       " 'OVER#V',\n",
       " 'PART',\n",
       " 'POST',\n",
       " 'PRE#PART',\n",
       " 'PRE#V',\n",
       " 'PREP',\n",
       " 'PRO:DEM',\n",
       " 'PRO:EXIST',\n",
       " 'PRO:INDEF',\n",
       " 'PRO:INT',\n",
       " 'PRO:OBJ',\n",
       " 'PRO:PER',\n",
       " 'PRO:POSS',\n",
       " 'PRO:REFL',\n",
       " 'PRO:REL',\n",
       " 'PRO:SUB',\n",
       " 'QN',\n",
       " 'UN#ADJ',\n",
       " 'UN#ADV',\n",
       " 'UN#N',\n",
       " 'UN#PART',\n",
       " 'UP#PART',\n",
       " 'UP#V',\n",
       " 'V'}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN: noun, common, singular or mass\n",
    "#     common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
    "#     investment slide humour falloff slick wind hyena override subhumanity\n",
    "#     machinist ...\n",
    "# NNP: noun, proper, singular\n",
    "#     Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
    "#     Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
    "#     Shannon A.K.C. Meltex Liverpool ...\n",
    "# NNPS: noun, proper, plural\n",
    "#     Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
    "#     Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
    "#     Apache Apaches Apocrypha ...\n",
    "# NNS: noun, common, plural\n",
    "#     undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
    "#     divestitures storehouses designs clubs fragrances averages\n",
    "#     subjectivists apprehensions muses factory-jobs ...\n",
    "\n",
    "set(addb_posset.keys()).difference(posset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to concat to embedding tensor \n",
    "pos_dict = {pos:i for (i,pos) in enumerate(posset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'CM': 1,\n",
       " 'COMP': 2,\n",
       " 'PRO:EXIST': 3,\n",
       " 'IN#ADJ': 4,\n",
       " 'PRE#PART': 5,\n",
       " '.': 6,\n",
       " 'PRE#V': 7,\n",
       " 'OVER#PART': 8,\n",
       " 'UN#ADV': 9,\n",
       " 'PRO:PER': 10,\n",
       " 'ADV:TEM': 11,\n",
       " '+/.': 12,\n",
       " 'V': 13,\n",
       " 'PRO:INT': 14,\n",
       " 'N': 15,\n",
       " 'PRO:POSS': 16,\n",
       " 'N:ADJ': 17,\n",
       " 'DET:DEM': 18,\n",
       " 'END': 19,\n",
       " 'PRO:INDEF': 20,\n",
       " '+\"/.': 21,\n",
       " 'DET:POSS': 22,\n",
       " 'OVER#V': 23,\n",
       " 'DET:ART': 24,\n",
       " 'INF': 25,\n",
       " 'OVER#N:GERUND': 26,\n",
       " 'META': 27,\n",
       " 'ON': 28,\n",
       " 'UP#V': 29,\n",
       " 'MID#N': 30,\n",
       " 'NEG': 31,\n",
       " 'MOD': 32,\n",
       " '+...': 33,\n",
       " 'PRO:SUB': 34,\n",
       " 'UN#PART': 35,\n",
       " 'PREP': 36,\n",
       " 'DET:NUM': 37,\n",
       " 'N:GERUND': 38,\n",
       " '+//?': 39,\n",
       " 'UN#ADJ': 40,\n",
       " 'COP': 41,\n",
       " 'N:PT': 42,\n",
       " 'AUX': 43,\n",
       " 'ADV': 44,\n",
       " 'OUT#PART': 45,\n",
       " '!': 46,\n",
       " 'PRO:OBJ': 47,\n",
       " 'ADJ': 48,\n",
       " 'N:PROP': 49,\n",
       " 'MINI#N': 50,\n",
       " '+/?': 51,\n",
       " '?': 52,\n",
       " 'POST': 53,\n",
       " 'N:LET': 54,\n",
       " 'UN#N': 55,\n",
       " 'UP#PART': 56,\n",
       " 'COORD': 57,\n",
       " 'QN': 58,\n",
       " 'GRAND#N': 59,\n",
       " 'CONJ': 60,\n",
       " '+..?': 61,\n",
       " 'PART': 62,\n",
       " 'BEG': 63,\n",
       " 'PRO:REL': 64,\n",
       " 'PRO:REFL': 65,\n",
       " 'NEO': 66,\n",
       " 'CO': 67,\n",
       " '+\".': 68,\n",
       " 'PRO:DEM': 69,\n",
       " '+//.': 70}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pos_dict,'pos_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOCAB EMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Blosc/bcolz\n",
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/renee/Documents/CT_Fa18/Spec/Trace'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile('./PretrainedWordEmb/glove.42B.300d.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./PretrainedWordEmb/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load pretrained glove (common crawl 42B tokens, 1.9M vocab, uncased, 300d vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = './FinalProj/PretrainedWordEmb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'{glove_path}/glove.42B.300d.txt', 'rb') as f:\n",
    "#     for l in f:\n",
    "#         line = l.decode().split()\n",
    "#         word = line[0]\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = []\n",
    "# idx = 0\n",
    "# word2idx = {}\n",
    "# vectors = bcolz.carray(np.zeros(1), rootdir=f'{glove_path}/glove.42B.300.dat', mode='w')\n",
    "\n",
    "# with open(f'{glove_path}/glove.42B.300d.txt', 'rb') as f:\n",
    "#     for l in f:\n",
    "#         line = l.decode().split()\n",
    "#         word = line[0]\n",
    "#         words.append(word)\n",
    "#         word2idx[word] = idx\n",
    "#         idx += 1\n",
    "#         vect = np.array(line[1:]).astype(np.float)\n",
    "#         vectors.append(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors = bcolz.carray(vectors[1:].reshape((-1,300)), rootdir=f'{glove_path}/glove.42B.300.dat', mode='w')\n",
    "# vectors.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(words, open(f'{glove_path}/glove.42B.300_words.pkl', 'wb'))\n",
    "# pickle.dump(word2idx, open(f'{glove_path}/glove.42B.300_idx.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.open(f'{glove_path}/glove.42B.300.dat')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pickle.load(open(f'{glove_path}/glove.42B.300_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(f'{glove_path}/glove.42B.300_idx.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNK token -- average of embeddings\n",
    "average_vec = np.mean(vectors, axis=0)\n",
    "# print(average_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'UNK' in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.append('UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1917494, 300)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.concatenate((vectors,np.reshape(average_vec,(1,300))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1917495"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx['UNK'] = len(vectors) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1917495"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "def get_glovembs(sample):\n",
    "    \n",
    "    def handle_contractions(x):\n",
    "        tokenizer = TreebankWordTokenizer()\n",
    "        x = tokenizer.tokenize(x)\n",
    "        x = ' '.join(x)\n",
    "        return x\n",
    "    \n",
    "    # preprocess acc to pretrained embeddings \n",
    "    # lower\n",
    "    # replace _, -\n",
    "    # rm contractions\n",
    "    # rm nonascii chars\n",
    "    \n",
    "    sample = [s for s in sample]\n",
    "    \n",
    "    preprocessample = [handle_contractions(t).split()[0] for t in [token.lower().replace('_','-') for token in sample]]\n",
    "    \n",
    "    \n",
    "    preprocessample = [''.join([i if ord(i) < 128 else '' for i in w]) for w in preprocessample]\n",
    "    \n",
    "    preprocessample = [t.translate(str.maketrans('', '', string.punctuation)) for t in preprocessample]\n",
    "    \n",
    "\n",
    "#     return set([word for word in preprocessample if word not in words])\n",
    "    # {w: vectors[word2idx[w]] for w in words}\n",
    "    return {sample[i]: torch.tensor(vectors[word2idx[preprocessample[i]]]) if preprocessample[i] in words else torch.tensor(vectors[word2idx['UNK']]) for i in range(len(sample))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceunks = get_glovembs(vocabset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '11alpha',\n",
       " '2ndteam',\n",
       " 'devicelogs',\n",
       " 'dontuse',\n",
       " 'electroniceven',\n",
       " 'envirmental',\n",
       " 'etccwas',\n",
       " 'gerslyn',\n",
       " 'intigral',\n",
       " 'monmarte',\n",
       " 'precomputer',\n",
       " 'preinternet',\n",
       " 'townno',\n",
       " 'unqua',\n",
       " 'windowdoors',\n",
       " 'wlodawski'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traceunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceunks = set()\n",
    "for word in vocabset:\n",
    "    if word not in words:\n",
    "        traceunks.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traceunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'liking' in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_vocab_embs = get_glovembs(vocabset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2125"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trace_vocab_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INADVERTENTLY OVERWROTE addb.vocab.glove.42B.300_words.pkl with trace.* !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(trace_vocab_embs, open(f'{glove_path}/trace.vocab.glove.42B.300_words.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addb_vocab_embs = get_glovembs(vocabset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(addb_vocab_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'UNK'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-89e94f37a4f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrace_vocab_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UNK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'UNK'"
     ]
    }
   ],
   "source": [
    "trace_vocab_embs['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace CLITIC emb with UNK token (mistaken for word 'clitic')\n",
    "# mistakenly saved as an np array...overwrote this key with torch.from_numpy(vocab_emb['CLITIC']): saved as addb.vocab.emb.glove.42B.300\n",
    "addb_vocab_embs['CLITIC'] = vectors[word2idx['UNK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(addb_vocab_embs, open(f'{glove_path}/addb.vocab.glove.42B.300_words.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "addbvocab = pickle.load(open(f'{glove_path}/addb.vocab.glove.42B.300_words.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addbvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(addbvocab) == list(addb_vocab_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabset_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list generated from preprocessing steps subsumed into get_glovembs()\n",
    "len(unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore CLITIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cookeiejar',\n",
       " \"i-don't-know\",\n",
       " 'cappdf',\n",
       " '//',\n",
       " '',\n",
       " '//',\n",
       " 'alrightie',\n",
       " '..',\n",
       " 'oh-boy',\n",
       " 'hmhunh',\n",
       " 'sewickly',\n",
       " 'tazmania-dutch',\n",
       " 'doctor-dick',\n",
       " 'how-about',\n",
       " 'god-bless-you',\n",
       " '',\n",
       " 'oh-dear',\n",
       " 'how-come',\n",
       " 'i-mean',\n",
       " 'what-about',\n",
       " 'joyce-kilmer',\n",
       " 'the-window-of-the-xxx',\n",
       " 'dave-branton',\n",
       " 'lots-of',\n",
       " 'a-lot-of',\n",
       " 'lee-a']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dl1010",
   "language": "python",
   "name": "dl1010"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
